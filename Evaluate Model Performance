from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns


y_test = test_set.classes

target_names =[]
for k,v in test_set.class_indices.items():
  target_names.append(f'{k}')

test_report = classification_report(y_test, predicted_classes, target_names=target_names)
print(f'Classification report: \n \n {test_report}')

conf_mat = confusion_matrix(y_test, predicted_classes)

def confusion_matrix_visualization(cm, tick_labels, file_name):
    
    plt.figure(figsize=(10, 10))
    
    class_percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]
    class_counts = ['{:.0f}'.format(value) for value in cm.flatten()]
    labels = [f'{v1}\n({v2})' for v1, v2,  in zip(class_percentages, class_counts)]
    labels = np.asarray(labels).reshape(4,4)
    
    ax = sns.heatmap(cm, annot=labels, cmap='Blues', fmt='')
    ax.set_title('\n\nConfusion Matrix\n', fontsize=20, fontweight='bold');
    ax.set_xlabel('\n\nPredicted Labels', fontsize=16)
    ax.set_ylabel('True Labels\n\n ', fontsize=16);
    ax.xaxis.set_ticklabels(tick_labels, fontsize=14)
    ax.yaxis.set_ticklabels(tick_labels, fontsize=14)
    
    plt.savefig(file_name)
    plt.show()


confusion_matrix_visualization(conf_mat, target_names, file_name='confusion_matrix.png')
